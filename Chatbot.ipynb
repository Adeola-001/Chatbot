{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adeola-001/Chatbot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yigBvIK0LAJ0"
      },
      "source": [
        "#### Installations and Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_Iv_iGx0HyB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1611bb3c-517d-476a-9f29-f889e2171241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: unstructured[html] in /usr/local/lib/python3.10/dist-packages (0.14.6)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (2.12.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (1.25.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (3.9.3)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (0.23.7)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured[html]) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[html]) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[html]) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[html]) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[html]) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[html]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[html]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[html]) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[html]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[html]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[html]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[html]) (2024.6.2)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (7.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (0.27.0)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (1.6.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (24.1)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (4.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[html]) (1.0.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured[html]) (4.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[html]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[html]) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[html]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[html]) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[html]) (1.2.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: unstructured 0.14.6 does not provide the extra 'html'\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install -qqq -U langchain-huggingface\n",
        "pip install -qqq -U langchain\n",
        "pip install -qqq -U langchain-community\n",
        "pip install -qqq -U faiss-cpu\n",
        "pip install pypdf\n",
        "pip install unstructured[html]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzi1DGiRLguh"
      },
      "source": [
        "#### Load data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LZ_H1eZ0ZkR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22dWtRpEdH4D"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTvaDQhCLV7H"
      },
      "source": [
        "#### Setting LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOoB-Dkh0onx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a7e767-c5e4-4126-f46d-de770d169a6f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(repo_id = hf_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqb4TJX8LdNv"
      },
      "source": [
        "#### Find data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vFqjhmye0qSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f317d0-9b88-4adf-e598-7aefa851cea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:42--  https://www.gutenberg.org/cache/epub/20709/pg20709.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 964182 (942K) [text/plain]\n",
            "Saving to: ‘/content/From_Pole_to_Pole’\n",
            "\n",
            "/content/From_Pole_ 100%[===================>] 941.58K  1.61MB/s    in 0.6s    \n",
            "\n",
            "2024-06-18 12:26:43 (1.61 MB/s) - ‘/content/From_Pole_to_Pole’ saved [964182/964182]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/From_Pole_to_Pole https://www.gutenberg.org/cache/epub/20709/pg20709.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zIJ24jApNzAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bffc8d-7c5f-4d8d-8e48-4b6871a94f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:43--  https://gutenberg.org/cache/epub/24407/pg24407.txt\n",
            "Resolving gutenberg.org (gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to gutenberg.org (gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206758 (202K) [text/plain]\n",
            "Saving to: ‘/content/The_Italian_Cook_Book’\n",
            "\n",
            "/content/The_Italia 100%[===================>] 201.91K   548KB/s    in 0.4s    \n",
            "\n",
            "2024-06-18 12:26:44 (548 KB/s) - ‘/content/The_Italian_Cook_Book’ saved [206758/206758]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/The_Italian_Cook_Book https://gutenberg.org/cache/epub/24407/pg24407.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ViqyVlWrOGs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea76526-5971-4521-8aea-024ff3eae7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:45--  https://gutenberg.org/cache/epub/42868/pg42868.txt\n",
            "Resolving gutenberg.org (gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to gutenberg.org (gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 661900 (646K) [text/plain]\n",
            "Saving to: ‘/content/A_Thousand_Ways_to_Please_a_Husband’\n",
            "\n",
            "/content/A_Thousand 100%[===================>] 646.39K  1.11MB/s    in 0.6s    \n",
            "\n",
            "2024-06-18 12:26:46 (1.11 MB/s) - ‘/content/A_Thousand_Ways_to_Please_a_Husband’ saved [661900/661900]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/A_Thousand_Ways_to_Please_a_Husband https://gutenberg.org/cache/epub/42868/pg42868.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "l_XO_O50OfJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6d0ad7-463e-4e8f-edf3-2cb386e59812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:46--  https://gutenberg.org/cache/epub/43745/pg43745.txt\n",
            "Resolving gutenberg.org (gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to gutenberg.org (gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548685 (536K) [text/plain]\n",
            "Saving to: ‘/content/With_the_Worlds_Great_Travellers’\n",
            "\n",
            "/content/With_the_W 100%[===================>] 535.83K  1.12MB/s    in 0.5s    \n",
            "\n",
            "2024-06-18 12:26:47 (1.12 MB/s) - ‘/content/With_the_Worlds_Great_Travellers’ saved [548685/548685]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/With_the_Worlds_Great_Travellers https://gutenberg.org/cache/epub/43745/pg43745.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/Natural_history_in_Anecdote https://www.gutenberg.org/cache/epub/37959/pg37959-images.html"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6W-pMSrGlMp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cd0cd9-71b4-4698-ebe2-8bcf671d910c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:47--  https://www.gutenberg.org/cache/epub/37959/pg37959-images.html\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1011465 (988K) [text/html]\n",
            "Saving to: ‘/content/Natural_history_in_Anecdote’\n",
            "\n",
            "/content/Natural_hi 100%[===================>] 987.76K  1.70MB/s    in 0.6s    \n",
            "\n",
            "2024-06-18 12:26:48 (1.70 MB/s) - ‘/content/Natural_history_in_Anecdote’ saved [1011465/1011465]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/International_Monthly_Magazine_of_Literature_Science_and_Art https://www.gutenberg.org/cache/epub/20955/pg20955-images.html"
      ],
      "metadata": {
        "collapsed": true,
        "id": "P4ymNdVEn527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12d7481-dc95-4250-a581-4ff8228d302a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:48--  https://www.gutenberg.org/cache/epub/20955/pg20955-images.html\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 904514 (883K) [text/html]\n",
            "Saving to: ‘/content/International_Monthly_Magazine_of_Literature_Science_and_Art’\n",
            "\n",
            "/content/Internatio 100%[===================>] 883.31K  1.52MB/s    in 0.6s    \n",
            "\n",
            "2024-06-18 12:26:49 (1.52 MB/s) - ‘/content/International_Monthly_Magazine_of_Literature_Science_and_Art’ saved [904514/904514]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/Travel_pic https://drive.google.com/file/d/12NU-O4qRGxetIqVbm5bichtiG1hmOeBP/view?usp=sharing"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU8-Nroo_cbJ",
        "outputId": "fed5c153-3121-4a9a-b6da-96782d16bded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 12:26:49--  https://drive.google.com/file/d/12NU-O4qRGxetIqVbm5bichtiG1hmOeBP/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.119.113, 108.177.119.100, 108.177.119.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.119.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/content/Travel_pic’\n",
            "\n",
            "/content/Travel_pic     [ <=>                ]  88.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-06-18 12:26:49 (3.76 MB/s) - ‘/content/Travel_pic’ saved [90221]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load all data"
      ],
      "metadata": {
        "id": "o0_TcNm3Mk6x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIUlOfj00syg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(\"/content/A_Thousand_Ways_to_Please_a_Husband\")\n",
        "documents = loader.load()\n",
        "loader1 = TextLoader(\"/content/From_Pole_to_Pole\")\n",
        "documents1 = loader1.load()\n",
        "loader2 = TextLoader(\"/content/The_Italian_Cook_Book\")\n",
        "documents2 = loader2.load()\n",
        "loader3 = TextLoader(\"/content/With_the_Worlds_Great_Travellers\")\n",
        "documents3 = loader3.load()\n",
        "loader4 = UnstructuredHTMLLoader(\"/content/Natural_history_in_Anecdote\")\n",
        "documents4 = loader4.load()\n",
        "loader5 = UnstructuredHTMLLoader(\"/content/International_Monthly_Magazine_of_Literature_Science_and_Art\")\n",
        "documents5 = loader5.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combine all documents\n",
        "all_documents = documents + documents1 + documents2 + documents3 + documents4 + documents5"
      ],
      "metadata": {
        "id": "dWYMnks3RIwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split text"
      ],
      "metadata": {
        "id": "g-lt5Rk2UHUr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwEyExyt2I6H"
      },
      "outputs": [],
      "source": [
        "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=250,chunk_overlap=25)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\",\"\\n\",\".\"]\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(all_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voINijOsZJKL"
      },
      "source": [
        "##### Testing and understanding embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyec3i6O0vcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ab92218d-8ba9-4eba-8f4b-f3e223602320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Embeddings\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n",
        "                                   cache_folder=embeddings_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZKyAko8n1tp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfa9492-9b26-451c-86cb-2ff1ccc5aeae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0017763564828783274,\n",
              " -0.05711093172430992,\n",
              " -0.03735116124153137,\n",
              " 0.035620108246803284,\n",
              " 0.008943280205130577,\n",
              " -0.065639927983284,\n",
              " 0.0797070786356926,\n",
              " 0.04645843803882599,\n",
              " 0.03400925174355507,\n",
              " 0.0417051762342453,\n",
              " -0.03569451719522476,\n",
              " -0.036951564252376556,\n",
              " -0.0495498850941658,\n",
              " 0.0060961428098380566,\n",
              " -0.06058715283870697,\n",
              " 0.007087082602083683,\n",
              " -0.034692250192165375,\n",
              " -0.1500234305858612,\n",
              " -0.03960023447871208,\n",
              " -0.0932970643043518,\n",
              " -0.030714672058820724,\n",
              " 0.03356964886188507,\n",
              " 0.11057154089212418,\n",
              " -0.06375357508659363,\n",
              " 0.03727630525827408,\n",
              " -0.03252798691391945,\n",
              " -0.0744345560669899,\n",
              " -0.032248206436634064,\n",
              " -0.017849203199148178,\n",
              " 0.0015820838743820786,\n",
              " -0.007907777093350887,\n",
              " 0.04140791296958923,\n",
              " 0.0769641175866127,\n",
              " 0.061364322900772095,\n",
              " -0.05584949254989624,\n",
              " -0.014074950478971004,\n",
              " 0.03136933594942093,\n",
              " 0.12421924620866776,\n",
              " -0.0316900871694088,\n",
              " 0.07236950844526291,\n",
              " -0.04126685857772827,\n",
              " -0.03985981643199921,\n",
              " -0.011754604056477547,\n",
              " 0.031479816883802414,\n",
              " 0.0023502360563725233,\n",
              " -0.05468861013650894,\n",
              " 0.05820082128047943,\n",
              " 0.00982898473739624,\n",
              " 0.03350327908992767,\n",
              " 0.05061565339565277,\n",
              " -0.13125237822532654,\n",
              " 0.05824815854430199,\n",
              " 0.045512352138757706,\n",
              " -0.058038558810949326,\n",
              " -0.04487979784607887,\n",
              " 0.030634751543402672,\n",
              " 0.04020903259515762,\n",
              " 0.08685076981782913,\n",
              " 0.012158863246440887,\n",
              " 0.06294253468513489,\n",
              " 0.005084161181002855,\n",
              " -0.06910085678100586,\n",
              " -0.057643111795186996,\n",
              " 0.010317245498299599,\n",
              " 0.06836551427841187,\n",
              " 0.019828949123620987,\n",
              " 0.005241371691226959,\n",
              " 0.04918050765991211,\n",
              " -0.03527696803212166,\n",
              " -0.02047865465283394,\n",
              " -0.005331684835255146,\n",
              " 0.031661298125982285,\n",
              " -0.02996658906340599,\n",
              " 0.08040355890989304,\n",
              " 0.04233191907405853,\n",
              " -0.03126191347837448,\n",
              " 0.01900891773402691,\n",
              " 0.014300256967544556,\n",
              " 0.07614707201719284,\n",
              " 0.006114174146205187,\n",
              " 0.06694252043962479,\n",
              " -0.11160826683044434,\n",
              " 0.008295178413391113,\n",
              " 0.055229976773262024,\n",
              " 0.03919728100299835,\n",
              " -0.037500254809856415,\n",
              " 0.007864645682275295,\n",
              " 0.0031272731721401215,\n",
              " -0.07357428222894669,\n",
              " -0.030983956530690193,\n",
              " 0.014324481599032879,\n",
              " -0.048378728330135345,\n",
              " 0.01062901969999075,\n",
              " -0.021166421473026276,\n",
              " -0.029636090621352196,\n",
              " 0.018388932570815086,\n",
              " -0.021152464672923088,\n",
              " -0.055468592792749405,\n",
              " 0.031841497868299484,\n",
              " 0.07571012526750565,\n",
              " -0.010048098862171173,\n",
              " -0.011397375725209713,\n",
              " 0.07900352030992508,\n",
              " 0.020891014486551285,\n",
              " 0.035236906260252,\n",
              " -0.042803775519132614,\n",
              " 0.008440930396318436,\n",
              " 0.024519268423318863,\n",
              " 0.03626403212547302,\n",
              " -0.03927968442440033,\n",
              " -0.013231790624558926,\n",
              " 0.07072433084249496,\n",
              " 0.05684484541416168,\n",
              " -0.02142559550702572,\n",
              " 0.10161230713129044,\n",
              " -0.06912333518266678,\n",
              " -0.1348056048154831,\n",
              " 0.01988166756927967,\n",
              " -0.0060094320215284824,\n",
              " -0.051881663501262665,\n",
              " 0.056175753474235535,\n",
              " 0.050654783844947815,\n",
              " -0.03473318740725517,\n",
              " 0.0627453476190567,\n",
              " 0.061882179230451584,\n",
              " 0.008294912986457348,\n",
              " -0.09781575947999954,\n",
              " -2.4301520013587173e-33,\n",
              " 0.014105206355452538,\n",
              " 0.02259869873523712,\n",
              " 0.06302977353334427,\n",
              " -0.014676416292786598,\n",
              " -0.03413677215576172,\n",
              " 0.02204744517803192,\n",
              " -0.09249003231525421,\n",
              " -0.013824536465108395,\n",
              " -0.005351736675947905,\n",
              " -0.00020671218226198107,\n",
              " -0.019401447847485542,\n",
              " 0.03439226374030113,\n",
              " -0.017889942973852158,\n",
              " 0.011302872560918331,\n",
              " -0.053484052419662476,\n",
              " 0.11923296004533768,\n",
              " -0.08328218758106232,\n",
              " -0.018090618774294853,\n",
              " -0.04469077289104462,\n",
              " 0.019964681938290596,\n",
              " 0.03549366444349289,\n",
              " -0.012472938746213913,\n",
              " 0.08017343282699585,\n",
              " 0.009930109605193138,\n",
              " -0.03580183535814285,\n",
              " 0.009367398917675018,\n",
              " 0.023054717108607292,\n",
              " -0.014509663917124271,\n",
              " 0.10554773360490799,\n",
              " 0.0061159897595644,\n",
              " -0.11144713312387466,\n",
              " 0.01522949431091547,\n",
              " -0.03244222700595856,\n",
              " -0.021429074928164482,\n",
              " 0.10039267688989639,\n",
              " 0.002232395811006427,\n",
              " -0.02945743314921856,\n",
              " -0.053034961223602295,\n",
              " 0.06582126021385193,\n",
              " 0.048012904822826385,\n",
              " 0.0011124643497169018,\n",
              " 0.012035404331982136,\n",
              " -0.006084954831749201,\n",
              " 0.03621344268321991,\n",
              " -0.03126634657382965,\n",
              " 0.049705881625413895,\n",
              " 0.04259813576936722,\n",
              " 0.003785858629271388,\n",
              " 0.03577514737844467,\n",
              " 0.05726296082139015,\n",
              " -0.0035888939164578915,\n",
              " 0.010705264285206795,\n",
              " 0.05535157397389412,\n",
              " -0.02318626455962658,\n",
              " 0.07818357646465302,\n",
              " 0.042164262384176254,\n",
              " 0.03723735734820366,\n",
              " -0.07124380022287369,\n",
              " 0.0692865177989006,\n",
              " -0.03268883749842644,\n",
              " -0.04104452580213547,\n",
              " 0.06707732379436493,\n",
              " -0.03938291221857071,\n",
              " 0.03478161618113518,\n",
              " -0.054436180740594864,\n",
              " 0.06104523316025734,\n",
              " -0.008234106004238129,\n",
              " 0.026237398386001587,\n",
              " 0.052222006022930145,\n",
              " 0.04663078114390373,\n",
              " 0.02820405550301075,\n",
              " 0.06562671810388565,\n",
              " 0.00024804030545055866,\n",
              " -0.1099657416343689,\n",
              " -0.04934532195329666,\n",
              " -0.008548328652977943,\n",
              " -0.07358373701572418,\n",
              " -0.01724182814359665,\n",
              " -0.02190350368618965,\n",
              " 0.026955416426062584,\n",
              " 0.08847281336784363,\n",
              " -0.06489547342061996,\n",
              " -0.02203206904232502,\n",
              " -0.08959642052650452,\n",
              " -0.03328430652618408,\n",
              " -0.061530306935310364,\n",
              " -0.003039564937353134,\n",
              " -0.03817497938871384,\n",
              " 0.009458773769438267,\n",
              " 0.011120294220745564,\n",
              " -0.05777491629123688,\n",
              " -0.04067029058933258,\n",
              " 0.036881450563669205,\n",
              " -0.03712517023086548,\n",
              " -0.018258675932884216,\n",
              " 1.8404827090129868e-33,\n",
              " -0.11639075726270676,\n",
              " 0.0015413459623232484,\n",
              " -0.06544911116361618,\n",
              " 0.11065857857465744,\n",
              " -0.00311581720598042,\n",
              " -0.005198408383876085,\n",
              " 0.02681668847799301,\n",
              " -0.07541657984256744,\n",
              " 0.056692227721214294,\n",
              " -0.006526270415633917,\n",
              " -0.02067599818110466,\n",
              " -0.056979529559612274,\n",
              " -0.030475357547402382,\n",
              " -0.09983239322900772,\n",
              " 0.08901002258062363,\n",
              " -0.06233338639140129,\n",
              " 0.02341931313276291,\n",
              " -0.040699344128370285,\n",
              " -0.10733091831207275,\n",
              " -0.08868937194347382,\n",
              " 0.06620901077985764,\n",
              " 0.0848681703209877,\n",
              " -0.08661549538373947,\n",
              " 0.016343042254447937,\n",
              " -0.012064115144312382,\n",
              " 0.0101102190092206,\n",
              " 0.0015276703052222729,\n",
              " -0.03783939406275749,\n",
              " -0.02582974173128605,\n",
              " 0.014275639317929745,\n",
              " -0.037982165813446045,\n",
              " 0.02643170766532421,\n",
              " -0.06490965187549591,\n",
              " -0.031596604734659195,\n",
              " -0.03789371997117996,\n",
              " 0.011242471635341644,\n",
              " -0.0021983736660331488,\n",
              " 0.01056001428514719,\n",
              " -0.06113462522625923,\n",
              " -0.010219968855381012,\n",
              " 0.018132012337446213,\n",
              " 0.03113405592739582,\n",
              " -0.039615485817193985,\n",
              " -0.017685730010271072,\n",
              " 0.04424221068620682,\n",
              " -6.319052045000717e-05,\n",
              " -0.01672063022851944,\n",
              " -0.0009374176152050495,\n",
              " -0.003342293668538332,\n",
              " -0.02610381692647934,\n",
              " 0.06047133728861809,\n",
              " 0.015976641327142715,\n",
              " -0.0015932286623865366,\n",
              " -0.038576673716306686,\n",
              " 0.006379973609000444,\n",
              " -0.028923099860548973,\n",
              " 0.035031989216804504,\n",
              " 0.021766696125268936,\n",
              " -0.029443327337503433,\n",
              " -0.005683721508830786,\n",
              " -0.058046553283929825,\n",
              " -0.08209973573684692,\n",
              " 0.08515065163373947,\n",
              " 0.047223035246133804,\n",
              " -0.030872106552124023,\n",
              " -0.07159774005413055,\n",
              " 0.029239360243082047,\n",
              " 0.0393792949616909,\n",
              " -0.020467394962906837,\n",
              " -0.06355136632919312,\n",
              " 0.0781615749001503,\n",
              " -0.05435371398925781,\n",
              " 0.04151545837521553,\n",
              " 0.008969264104962349,\n",
              " -0.060275644063949585,\n",
              " 0.1114770919084549,\n",
              " -0.0685972198843956,\n",
              " 0.007070132531225681,\n",
              " -0.05503203347325325,\n",
              " 0.03704279661178589,\n",
              " -0.023843206465244293,\n",
              " -0.13735444843769073,\n",
              " 0.12432029843330383,\n",
              " 0.03937917575240135,\n",
              " -0.0031728274188935757,\n",
              " 0.05863947048783302,\n",
              " -0.005094728898257017,\n",
              " -0.01233758870512247,\n",
              " -0.07828252762556076,\n",
              " 0.05370442569255829,\n",
              " -0.02198130451142788,\n",
              " -0.061211928725242615,\n",
              " -0.057354215532541275,\n",
              " 0.023101868107914925,\n",
              " 0.007872904650866985,\n",
              " -1.3982135449452926e-08,\n",
              " -0.03700204938650131,\n",
              " -0.03672095760703087,\n",
              " -0.012547324411571026,\n",
              " -0.037922509014606476,\n",
              " 0.006810939870774746,\n",
              " -0.056236762553453445,\n",
              " 0.0012996656587347388,\n",
              " 0.0983801931142807,\n",
              " -0.004456846974790096,\n",
              " -0.01441158913075924,\n",
              " 0.12951067090034485,\n",
              " 0.0254513006657362,\n",
              " 0.013050636276602745,\n",
              " 0.05829460546374321,\n",
              " 0.12247524410486221,\n",
              " 0.05499380826950073,\n",
              " 0.11300776153802872,\n",
              " -0.005237051285803318,\n",
              " -0.03623688220977783,\n",
              " 0.050299156457185745,\n",
              " 0.02263554558157921,\n",
              " 0.006927938666194677,\n",
              " 0.0031040573958307505,\n",
              " 0.044941507279872894,\n",
              " -0.022516265511512756,\n",
              " 0.016863249242305756,\n",
              " -0.0018214209703728557,\n",
              " 0.027416128665208817,\n",
              " -0.030444739386439323,\n",
              " 0.09207713603973389,\n",
              " -0.037166230380535126,\n",
              " 0.024783268570899963,\n",
              " -0.022236235439777374,\n",
              " 0.03734390065073967,\n",
              " 0.0960877388715744,\n",
              " -0.03289460018277168,\n",
              " 0.0013071270659565926,\n",
              " 0.041877418756484985,\n",
              " -0.002815710846334696,\n",
              " 0.007015880197286606,\n",
              " -0.0799177810549736,\n",
              " 0.06667116284370422,\n",
              " 0.03251148387789726,\n",
              " 0.05422155559062958,\n",
              " 0.03255494683980942,\n",
              " -0.005802823696285486,\n",
              " -0.02340410277247429,\n",
              " 0.09176314622163773,\n",
              " 0.021095970645546913,\n",
              " 0.03269810229539871,\n",
              " -0.002410759450867772,\n",
              " 0.010115223936736584,\n",
              " -0.013592271134257317,\n",
              " 0.0046747843734920025,\n",
              " 0.04035618528723717,\n",
              " -0.05012824758887291,\n",
              " 0.012141155079007149,\n",
              " -0.01428341306746006,\n",
              " -0.157694473862648,\n",
              " 0.05085311084985733,\n",
              " 0.01599123887717724,\n",
              " -0.028400208801031113,\n",
              " 0.04380134493112564,\n",
              " -0.07374034076929092]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "#example of embedding\n",
        "test_text = \"Why do data scientists make great comedians?\"\n",
        "query_result = embeddings.embed_query(test_text)\n",
        "query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8GksTlh5ikk"
      },
      "source": [
        "#### Creating Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz_F6b5g1-4x"
      },
      "outputs": [],
      "source": [
        "vector_db = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44TyMUFA2Cep"
      },
      "outputs": [],
      "source": [
        "vector_db.save_local(\"/content/faiss_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJBaxBK22Qlv"
      },
      "outputs": [],
      "source": [
        "# new_db = FAISS.load_local(\"/content/faiss_index\", embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LusaukpuMNxY"
      },
      "source": [
        "You can also search your database to see which vectors are close to your input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXaMtYhH2SP0",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206773d2-961d-4f24-a088-bcb19e0454b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='=Small Cakes= (Fourteen cakes)\\n\\n    1-1/4 C-sugar\\n    1/3 C-butter\\n    2 C-flour\\n    4 t-baking powder\\n    1/8 t-salt\\n    2/3 C-milk\\n    1 t-vanilla\\n    1/2 t-lemon extract\\n    2 egg-whites\\n\\nCream the butter, add the sugar slowly and continue creaming. Mix and\\nsift the flour, baking powder and salt and add these and the milk,\\nvanilla and lemon extracts to the butter and sugar. Mix well and beat\\ntwo minutes. Beat the egg-whites till very stiff and fold these very\\ncarefully into the cake mixture. When thoroughly mixed, fill the cake\\npans (which have been prepared with waxed paper) two-thirds of an inch\\ndeep with the mixture.\\n\\nBake twenty-five minutes in a moderate oven, allow to stand five\\nminutes, then slip a knife around the edges and remove the cake\\ncarefully from the pan. Turn over, remove the paper and allow the cake\\nto cool. Ice on the bottom side. When ready for serving, cut in two-inch\\nsquares.\\n\\n\\n=Bettina Icing=\\n\\n1 egg-white 1 T-cream 1 t-vanilla 1/2 t-lemon extract 2 C-powdered sugar\\n\\nBeat the egg-white add part of the sugar. Add the cream, vanilla and\\nlemon extracts. Keep beating. Add the rest of the sugar gradually. (A\\nlittle more sugar may be needed.) Beat the icing till very fluffy and\\nuntil it will spread without running off the cake. Spread each layer.\\n\\n\\n\\n\\nCHAPTER CXXVII\\n\\nA SHAMROCK LUNCHEON\\n\\n\\nBETTINA was entertaining \"the crowd\" at a shamrock luncheon, and each\\nguest, to show her enthusiasm for the charms of \"ould Ireland,\" was\\nwearing somewhere upon her gown, a bit of green.\\n\\nA green basket filled with white carnations and green foliage stood in\\nthe center of the table. White glass candlesticks with green shades also\\ncarried out the color scheme, while white crocheted favor baskets,\\nfilled with dainty green candies, were at each plate. The table was set\\nfor six.\\n\\nThe name cards were white shamrocks outlined with green ink and edged\\nwith gilt, and the name on each was written in green.\\n\\nBettina used green ferns for decoration in every possible place where\\nthey might add to the attractiveness of the table, under the glass\\ndishes and around the baskets containing rolls, cakes and croutons.\\n\\n\"You might be Irish yourself, Bettina,\" said Mary, \"you have such a\\nfeeling for green! And isn\\'t the table lovely, girls!\"\\n\\nFor luncheon Bettina served:\\n\\n                         Grapefruit Cocktail\\n    Cream of Celery Soup                     Shamrock Croutons\\n        Bettina Meat Timbales                  Brown Sauce\\n                         Asparagus on Toast\\n                   Mashed Sweet Potato Croquettes\\n            Shamrock Rolls                   Mint Jelly\\n               Pepper Salad              Sandwiches\\n                   Bombe Glace   Shamrock Cakes\\n                              Coffee\\n                         Shamrock Candies\\n\\n\\nBETTINA\\'S RECIPES\\n\\n(All measurements are level)\\n\\n\\n=Grapefruit Cocktail= (Six portions)\\n\\n    2 grapefruit\\n    1/3 C-sugar\\n    6 green cherries\\n    Smilax or fern leaves\\n\\nPeel the grapefruit, remove the white part and the tough membrane,\\nleaving the fruit. Cut with the scissors into one-inch cubes. Place in a\\nbowl, add the sugar and allow to stand in a cold place for one hour.\\nArrange the servings in six sherbet glasses. Place one green cherry on\\nthe top of each and garnish the plate with smilax or a fern leaf. Stand\\nthe sherbet glasses on a paper doily on a small serving plate. Arrange a\\nbit of the green leaf under the sherbet glass (on top of the doily) so\\nthat the green color will be visible through the glass.\\n\\n\\n=Cream of Celery Soup= (Six portions)\\n\\n    2/3 C-celery, cut fine\\n    1-1/2 C-water\\n    4 T-butter\\n    6 T-flour\\n    2-1/2 C-milk\\n    2 t-salt\\n    1/4 t-paprika\\n    1 t-chopped parsley\\n    2 T-whipped cream', metadata={'source': '/content/A_Thousand_Ways_to_Please_a_Husband'}),\n",
              " Document(page_content='=Fancy Cakes= (Eighteen cakes)\\n\\n    1/2 C-butter\\n    1 C-sugar\\n    8 egg-yolks\\n    1/2 C-milk\\n    1-3/4 C-flour\\n    2 t-baking powder\\n    2 t-lemon extract\\n\\nCream the butter, add the sugar and mix well. Beat the egg-yolks until\\nvery thick, and add to the first mixture. Mix and sift together the\\nflour and baking-powder and add the milk alternately with the flour\\nmixture, beating well. Beat two minutes after mixing. Add the extract.\\nPour to the thickness of one inch into flat pans lined with buttered\\npaper. Bake twelve minutes in a moderate oven. Remove from the fire and\\nwhen cool, cut into shapes with fancy animal cutters. The individual\\ncakes may be iced if desired.\\n\\n\\n\\n\\nCHAPTER CXLI\\n\\nPLANNING A LUNCHEON\\n\\n\\n\"IT won\\'t be hard, Ruth, if you plan it out in detail several days\\nbefore. Decide on the menu, and if you find that some one dish is going\\nto cause more trouble than it\\'s worth, plan something else in its\\nplace.\"\\n\\n\"If it weren\\'t for Aunt Gertrude I shouldn\\'t worry at all, but she is\\nsuch a wonderful housekeeper! And I am determined that Mother sha\\'n\\'t\\nhave one bit of the responsibility. She\\'s to feel herself just as much a\\nguest as Aunt Gertrude.\"\\n\\n\"I think it\\'s a lovely thing for you to do, Ruth. Now let me tell you\\nhow I think you should go about it. Make a visit to your grocery store\\nor to the market tomorrow, and notice the good things that are in season\\nand inexpensive. Build your menu around them. When you get home, sit\\ndown with a paper and pencil and plan everything out. Go into detail,\\neven if it takes several hours of planning. It will be well worth it. I\\ndon\\'t mean by that an elaborate luncheon; it ought to be a simple and\\ndelicious one, but complete in every detail. When I plan, I write down\\nthe things that I can do the day before, and even the day before that.\\nYou know there are always so many things to see to--polishing the silver\\nand writing the name cards and seeing that the table linen is in order.\\nIt ought to be planned so that the day of the party won\\'t be crowded\\nfull of \\'last minute things.\\' Come into the kitchen with me, Ruth; I\\nmust baste my pork tenderloin.\"\\n\\nThat night Bettina served:\\n\\n    Pork Tenderloin                      Baked Potatoes\\n           Bread                          Butter\\n                       Raspberry Jam\\n       Vegetable Salad                Salad Dressing\\n                      Tapioca Pudding\\n                           Coffee\\n\\n\\nBETTINA\\'S RECIPES\\n\\n(All measurements are level)\\n\\n\\n=Pork Tenderloin= (Three portions)\\n\\n    1 lb. pork tenderloin\\n    1 t-salt\\n    2 T-water\\n    1/4 t-paprika\\n    1 t-chopped parsley\\n    1 T-lemon juice\\n\\nHave the tenderloin cut in two-inch pieces and flattened. Place these in\\na small baking dish. Sprinkle with salt and paprika and add the water.\\nCover, and cook in a moderate oven for thirty-five minutes. Turn and\\nbaste frequently. When done, place on a heated platter, pour the parsley\\nand lemon juice over the top and serve immediately.\\n\\n\\n=Vegetable Salad= (Three portions)\\n\\n    1 tomato\\n    9 slices of cucumber\\n    2 T-chopped onion\\n    1 T-chopped pimento\\n    1 t-salt\\n    1/4 t-paprika\\n    2 T-chopped green pepper\\n    2 T-nut meats\\n    3 lettuce leaves\\n\\nWash the lettuce carefully and arrange on individual serving dishes.\\nPlace upon each lettuce leaf a slice of tomato, three slices of cucumber\\nand one-third of each of the other ingredients. Sprinkle with salt and\\npaprika. Pour the salad dressing over the top and serve very cold.\\n\\n\\n=Bettina Salad Dressing=\\n\\n    2 egg-yolks\\n    1 T-sugar\\n    1/2 t-salt\\n    2 T-flour\\n    1/4 C-vinegar\\n    1/3 C-sour cream\\n    2 T-pimento liquor (the juice from the can)\\n\\nBeat the egg-yolks, add the sugar, salt and flour. Mix well and add the\\nvinegar, pimento liquor and water. Cook in a double boiler until very\\nthick. When cool, add the sour cream, and pour over the salad.\\n\\n\\n\\n\\nCHAPTER CXLII\\n\\nTHE NEW CAR', metadata={'source': '/content/A_Thousand_Ways_to_Please_a_Husband'}),\n",
              " Document(page_content='Now in order to prepare the quince-cake spread it on a board to the\\nthickness of about a silver dollar and dry it in the sun covered with\\ncheese cloth to keep away the flies. When it is dry cut it in the form\\nof chocolate tablets and remove each piece from the board passing the\\nblade of a knife underneath.\\n\\nIf it is wished to make it crisp, melt about three and a half pounds of\\ngranulated sugar with two tablespoonfuls of water and when the sugar has\\nboiled enough to \"make the thread\" smear every one of the little quince\\ncakes with it. If the sugar becomes too hard during the operation put it\\nback on the fire with a little water and make it boil again. When the\\nsugar is dry on one side and on the edge, smear the other side.\\n\\n\\n196\\n\\nPORTUGUESE CAKE\\n\\n(Focaccia alla Portoghese)\\n\\n  Sweet almonds, five ounces.\\n  Granulated sugar, five ounces.\\n  Potato meal, one and a half ounce.\\n  Three eggs.\\n  One big orange or two small.\\n\\nFirst mix the yolks of the eggs with the sugar, then add the flour, then\\nthe almonds skinned and chopped fine, then the orange juice (through a\\ncolander) then a taste of orange peel. Finally add to the mixture the\\nwhites of the eggs well beaten. Put in a paper mold greased evenly with\\nbutter, with a thickness of about an inch and bake in a very moderately\\nhot oven. After baked, cover with a white glaze or frost, made with\\npowdered sugar, lemon juice and the white of eggs.\\n\\n\\n197\\n\\nMACAROONS\\n\\n(Amaretti)\\n\\nI\\n\\n  Granulated sugar, nine ounces.\\n  Sweet almonds, three and a half ounces.\\n  Bitter almonds, half of the above quantity.\\n  Whites of egg, two.\\n\\nSkin and dry the almonds, then chop them very fine. Mix the sugar and\\nthe whites of egg and stir for about half an hour, then add the almonds\\nto form a rather hard paste. Of this make little balls, as large as a\\nsmall walnut. If the paste is too soft add a little butter, if too hard\\nadd a little white of egg, this time beaten. Were it desired to give the\\nmacaroons a brownish color, mix with the paste a little burnt sugar.\\n\\nAs you form the little ball, that you will flatten to the thickness of\\none third of an inch, put them over wafers or on pieces of paper or in a\\nbaking tin greased with butter and sprinkled with half flour and half\\npowdered sugar. Dispose them at a certain distance from one another as\\nthey will enlarge and swell, remaining empty inside.\\n\\nBake in an oven moderately hot.\\n\\nII\\n\\n  Powdered sugar, ten and a half ounces.\\n  Sweet almonds, three ounces.\\n  Bitter almonds, one ounce.\\n  Two whites of egg.\\n\\nSkin the almonds and dry them in the sun or on the fire, then chop and\\ngrind very fine with one white of egg poured in various times. When this\\nis done, put half of the sugar, stirring and kneading with your hand.\\nThen pour everything in a large bowl and, always mixing, add half of the\\nother white of egg, then the other half of the sugar and finally the\\nother half of the white.\\n\\nIn this way an homogenous mixture will be obtained of the right\\nfirmness. Shake into a kind of a stick and cut it in rounds all equal,\\none third of an inch thick. Take them up one by one with moistened\\nfingers and make little balls as large as a walnut. Flatten them to the\\nthickness of a third of an inch and for the rest proceed as said above,\\nbut dust with powdered sugar before putting in a hot oven.\\n\\nWith this dose about thirty macarons can be obtained.\\n\\n\\n198\\n\\nFARINA CAKES\\n\\n(Pasticcini di semolino)\\n\\n  Farina, six and a half ounces.\\n  Sugar, three and a half ounces.\\n  Pine-seeds, two ounces.\\n  Butter, a small piece.\\n  Milk, one quart.\\n  Four eggs.\\n  A pinch of salt.\\n  Taste of lemon peel.\\n\\nCook the farina in the milk and when it begins to thicken pour the\\npine-seeds, previously chopped fine and pounded with the sugar, then the\\nbutter and the rest, less the eggs which must be put in last when the\\nmixture has completely cooled. Then place the whole well mixed in little\\nmolds, greased evenly with butter and sprinkled with bread crumbs ground\\nfine, and bake.\\n\\n\\n199\\n\\nRICE TART\\n\\n(Torta di riso)', metadata={'source': '/content/The_Italian_Cook_Book'}),\n",
              " Document(page_content='Bake in a tin where the mixture comes about one inch and a half thick,\\npreviously greasing the tin with cold butter and sprinkle with powdered\\nsugar mixed with flour.\\n\\nIn these cakes with beaten whites the following method can also be\\nfollowed: mix and stir first the yolks with the sugar, then put the\\nflour then, after a good kneading, beat the whites until they are firm,\\npour two tablespoonfuls to soften the mixture, then the rest little by\\nlittle.\\n\\n\\n192\\n\\nCAKE MADELEINE\\n\\n(Pasta Maddalena)\\n\\n  Sugar, four and a half ounces,\\n  Flour, three ounces,\\n  Butter, one ounce,\\n  Egg-yolks, four,\\n  Whites of eggs, three,\\n  A pinch of bi-carbonate of soda,\\n  A taste of lemon peel.\\n\\nFirst mix and stir the yolks with the sugar and when they have become\\nwhitish, add the flour and stir for fifteen minutes more. Mix with the\\nbutter, melting or softening it fine if it is hard and finally add the\\nwhites when they are well beaten. The flour must be previously dried in\\nthe sun or on the fire.\\n\\nThis cake may be given different shapes, but keep it always thin and in\\nlittle volume. It can be put in little molds greased with butter and\\nsprinkled with flour, or else in a baking tin, keeping it not more than\\nhalf an inch thick, and cutting it after baking in the shape of diamonds\\nand dusting with powdered sugar.\\n\\n\\n193\\n\\nALMOND CRISP-TART\\n\\n(Croccante)\\n\\n  Sweet almonds, four and a half ounces.\\n  Granulated sugar, three and a half ounces.\\n\\nSkin the almonds, divide the two parts and cut each part into small\\npieces. Put these almonds so cut at the fire and dry them until they\\ntake a yellowish color, but do not toast. Meanwhile put the sugar on the\\nfire in a saucepan and, when it is perfectly melted, pour the almonds\\nhot and already slightly browned. Now lower the fire and be careful not\\nto allow the compound to be overdone. The precise point is known when\\nthe mixture acquires a cinnamon color. Then pour little by little in a\\ncold mold, previously greased with butter or oil. Press with a lemon\\nagainst the walls of the mold, making the mixture as thin as possible.\\nRemove from the mold when perfectly cooled and, if it is difficult to do\\nso, dip the mold in boiling water.\\n\\nThe almonds can also be dried in the sun and chopped fine, adding a\\nsmall piece of butter when they are in the sugar.\\n\\n\\n194\\n\\nWAFER BISCUITS\\n\\n(Cialdoni)\\n\\nPut in a kettle:\\n\\n  Flour, three ounces.\\n  Brown sugar, one ounce.\\n  Lard virgin, half an ounce.\\n  Cold water, seven tablespoonfuls.\\n\\nFirst dilute the flour and the sugar in the water, then add the lard.\\n\\nPut on the fire the iron for waffles or better an appropriated iron for\\nflattened wafers. When it is quite hot open it and place each time half\\na tablespoonful of the paste. Close the iron and press well. Pass over\\nthe fire on both sides, trim all around with a knife and open the iron\\nwhen you see that the wafer is browned. Then detach it from one side of\\nthe iron and hot as it is roll it on the iron itself or on a napkin\\nusing a little stick. This operation must be made with great rapidity\\nbecause if the wafer gets cold, it cannot be rolled.\\n\\nShould the wafers remain attached to the iron, grease it from time to\\ntime, and if they are not firm enough, add a little flour.\\n\\nThese wafer-biscuits are generally served with whipped cream.\\n\\n\\n195\\n\\nQUINCE CAKE\\n\\n(Cotognata)\\n\\nThe ingredients are about six pounds of quinces and four pounds of\\ngranulated sugar.\\n\\nPut on the fire the apples covered with water, and when they begin to\\ncrack remove them, skin and scrape to put together all the pulp. Rub the\\nlatter through a sieve. Put back the pulp on the fire with the sugar and\\nstir continually in order that it may not attack to the bottom of the\\nkettle. It will be enough to boil for seven or eight minutes and remove\\nwhen it begins to form pieces when lifted with the ladle.', metadata={'source': '/content/The_Italian_Cook_Book'})]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "vector_db.similarity_search(\"Cake\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWqdH2r-6jZs"
      },
      "source": [
        "#### Set the template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBFbpYXs2UGU"
      },
      "outputs": [],
      "source": [
        "input_template = \"\"\"Answer the question based only on the following context. Keep your answers short and succinct.\n",
        "\n",
        "Context to answer question:\n",
        "{context}\n",
        "\n",
        "Question to be answered: {question}\n",
        "Response:\"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(template=input_template,\n",
        "                        input_variables=[\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xc-pw4-MgUf"
      },
      "source": [
        "#### RAG - chaining it all together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLRn4EUl29O5"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 2}), # top 2 results only, speed things up\n",
        "    return_source_documents = True,\n",
        "    chain_type_kwargs = {\"prompt\": prompt},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4uExwKi3AcM",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8f4529-2861-4ae4-817f-34d875765572"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is the capital of Greece',\n",
              " 'result': ' Mitylene is not the capital of Greece, it is nearer to Athens than Constantinople and its population is almost wholly Greek, but it is not mentioned as the capital of Greece in the context. The capital of Greece is Athens.',\n",
              " 'source_documents': [Document(page_content='TEMPLE OF JUPITER OLYMPUS.\\n\\nANOTHER VIEW OF THE TEMPLE OF JUPITER OLYMPUS.\\n\\nOf two views of the temple of Jupiter Olympus, Mr. Cook chose that in\\r\\nwhich the Acropolis is seen in the distance. The three lofty Corinthian\\r\\ncolumns in the other engraving are diminished to the scale of the arch,\\r\\nwhile the Acropolis, from its greater complexity of parts, adds,\\r\\nperhaps, something of a quality in which the subject is rather wanting.\\r\\n\"I am not sure,\" says Mr. Cook, \"that the remains of the temple of\\r\\nJupiter Olympus are not the most impressive which Athens offers to the\\r\\neye and heart of the traveller, partly from their abstract grandeur—a\\r\\ngrandeur derived from every element which could contribute to such an\\r\\nend—and partly from a position than which it would be impossible to\\r\\nconceive any thing more magnificent. The gigantic columns struck me with\\r\\na sense of awe and bewilderment, almost oppressive; they consist, as may\\r\\nbe seen by the engraving, of sixteen, the sole representatives of the\\r\\none hundred and twenty which once formed this mightiest of Athenian\\r\\ntemples. The least thoughtful person could scarcely avoid the question\\r\\nof where and how the remaining one hundred and four of these enormous\\r\\nmasses can have vanished; and assisted by the fullest information which\\r\\nis to be acquired on the subject, it remains a matter of wonder to all.\\r\\nThat time itself has had but little to answer for, the almost perfect\\r\\npreservation of portions is sufficient to prove; in some cases the\\r\\nflutings are as sharp and clean as when the hand of the sculptor left\\r\\nthem, while, more generally, they bear disgraceful evidence of ill-usage\\r\\nof every kind, from that of the cannon ball to the petty mischief of\\r\\nwanton idleness. The proportion of these columns is quite perfect, and\\r\\nthe mind is lost in charmed wonder, as wandering from part to part of\\r\\nthe vast platform, it is presented at every step with combinations\\r\\nperpetually changing, yet always beautiful. So difficult do I find it to\\r\\ndetermine from what point of view these ruins are seen to the greatest\\r\\nadvantage, that I have appended two engravings, from which the reader\\r\\nmay select that which best conveys to him the magnificence[Pg 9] of the\\r\\nstructure which has been thus slightly described.\" The temple of Jupiter\\r\\nOlympus was one of the first conceived, and the last executed of the\\r\\nsacred monuments of Athens. It was begun by Pisistratus, but not\\r\\nfinished till the time of the Roman emperor Adrian, seven hundred years\\r\\nafterwards.\\n\\nMONUMENT OF LYSICRATES.', metadata={'source': '/content/International_Monthly_Magazine_of_Literature_Science_and_Art'}),\n",
              "  Document(page_content='The valleys are very fertile, and if they are not \"covered over with\\ncorn,\" they have large plantations of fig and other fruit-trees; while\\nthe olive-orchards, if they do not pour out \"rivers of oil,\" yet yield\\nit in such abundance as makes it the chief industry of the island,\\nand furnishes a source of wealth to the thrifty inhabitants. All these\\nvarieties of vegetation were now in their perfect bloom, as it was the\\nmiddle of May, when in the East the earth rejoices in the freshness\\nof spring-time. As we sailed along these shores in the twilight, I\\nwondered if a fairer Arcadia ever rose out of the waters of this\\ntroubled world.\\n\\nThe island of Lesbos has an important place in Greek history, even at\\nits most remote period. As early as the siege of Troy it had a large\\npopulation, and continued to flourish for centuries.\\n\\nWhen Athens had its Academy, Lesbos had its schools of philosophy,\\nwhich attracted the wise men of Greece. It was even more famous as the\\nbirthplace of a school of lyric poets,--\\n\\n    \"Where burning Sappho lived and sung,\"\\n\\nand others whose stirring odes live in the collections of Greek poetry.\\n\\nWhen the Romans became masters of the East they were attracted by\\nthe beauty of the Greek islands. Their fondness for a mild-tempered\\nclimate, such as is found in greatest perfection in an island lying in\\nsummer seas, where the temperature of the sea softens alike the heat\\nof summer and the cold of winter,--which led them to choose Ischia\\nand Capri, at the mouth of the Bay of Naples, as favorite abodes of\\nImperial luxury,--led them, when sent to distant provinces, to choose\\nLesbos, which Tacitus describes in a line as \"_insula nobilis et\\namoena_\" [a noble and pleasant island], as one of those semi-royal\\nretreats in which a Roman governor might pass his splendid exile, and\\nalmost forget his absence from the imperial city....\\n\\nOn the whole, Mitylene seems to me the most important, as well as the\\nmost beautiful, island of the Archipelago, and this very beauty and\\nfertility but increase the regret that it should be under the rule of\\nTurkey when it ought to belong to Greece. It is nearer to Athens than\\nto Constantinople. It lies midway between the shores of Asia Minor and\\nthe mainland of Greece, and its population is almost wholly Greek. It\\nis Greek in religion. One coming into Mitylene sees neither mosque nor\\nminaret. Thus it is Greek by its position, its history, and its people.\\nIf ever there comes a time of \"the restitution of all things,\" the\\nisland will be taken from Turkey and restored to its natural place as\\npart of the young kingdom of Greece.\\n\\n\\n\\n\\nTHE SERAGLIO ON THE GOLDEN HORN.\\n\\nEDWARD DANIEL CLARKE.\\n\\n       [Dr. Clarke, in his animated descriptions of the countries of\\n     Eastern Europe, gives picturesque accounts of what is to be seen\\n     in Constantinople and other portions of the Sultan\\'s domain.\\n     Perhaps the most interesting of these is his description of a\\n     stolen visit to the seraglio, a tabooed place only to be inspected\\n     at imminent risk of life. Our traveller managed to see it quite\\n     thoroughly, as will be seen from his story of the dangerous\\n     enterprise.]\\n\\n\\nI eagerly sought an opportunity to examine the interior of the\\nseraglio; and, difficult as the undertaking may seem, soon found the\\nmeans of its accomplishment. The harmony existing between England and\\nthe Porte at that critical juncture when Egypt was to be restored\\nto the Turks by the valor of our troops, greatly facilitated the\\nenterprise. I felt convinced that within the walls of the seraglio many\\ninteresting antiquities were concealed from observation; and I was not\\ndisappointed.\\n\\nThe first place to which my observations were directed was the\\nimperial armory; and here, to my great gratification, I beheld the\\nweapons, shields, and military engines of the Greek emperors, exactly\\ncorresponding with those represented on the medals and bas-reliefs of\\nthe ancients, suspended as trophies of the capture of the city by the\\nTurks....', metadata={'source': '/content/With_the_Worlds_Great_Travellers'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "answer = qa_chain.invoke(\"What is the capital of Greece\")\n",
        "\n",
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1o03oJezkK"
      },
      "source": [
        "#### Setting up chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ecrZ5zwklpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8a6e8a-1848-4309-84a4-c5d11f969e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "llm = HuggingFaceEndpoint(repo_id=hf_model)\n",
        "\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n",
        "                                   cache_folder=embeddings_folder)\n",
        "\n",
        "vector_db = FAISS.load_local(\"/content/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key = 'chat_history',\n",
        "                                  return_messages = True,\n",
        "                                  output_key = 'answer')  # Set output_key to 'answer'\n",
        "\n",
        "template = \"\"\"You are a nice chatbot having a conversation with a human. Answer the question based only on the following context and previous conversation. Keep your answers short and succinct.\n",
        "\n",
        "Previous conversation:\n",
        "{chat_history}\n",
        "\n",
        "Context to answer question:\n",
        "{context}\n",
        "\n",
        "New human question: {question}\n",
        "Response:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template = template,\n",
        "                        input_variables = [\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14iJS2xdbOag"
      },
      "outputs": [],
      "source": [
        "# chain\n",
        "chain = ConversationalRetrievalChain.from_llm(llm,\n",
        "                                              retriever = retriever,\n",
        "                                              memory = memory,\n",
        "                                              return_source_documents = True,\n",
        "                                              combine_docs_chain_kwargs = {\"prompt\": prompt})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLOyvvflhQBK"
      },
      "source": [
        "#### Explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "348Hs2oibOXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a03ee7e9-74c2-4622-c3ba-e76519ea0986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Give me a cake recipe?',\n",
              " 'chat_history': [HumanMessage(content='Give me a cake recipe?'),\n",
              "  AIMessage(content=' Here is a recipe for Small Cakes from the provided context:\\n\\nIngredients:\\n- 1-1/4 C sugar\\n- 1/3 C butter\\n- 2 C flour\\n- 4 t baking powder\\n- 1/8 t salt\\n- 2/3 C milk\\n- 1 t vanilla\\n- 1/2 t lemon extract\\n- 2 egg-whites\\n\\nInstructions:\\n1. Cream the butter, add the sugar slowly and continue creaming.\\n2. Mix and sift the flour, baking powder and salt and add these and the milk, vanilla and lemon extracts to the butter and sugar. Mix well and beat 2 minutes.\\n3. Beat the egg-whites till very stiff and fold these very carefully into the cake mixture.\\n4. Fill the cake pans (prepared with waxed paper) 2/3 inches deep with the mixture.\\n5. Bake 25 minutes in a moderate oven.\\n6. Allow to stand 5 minutes, then slip a knife around the edges and remove the cake carefully from the pan.\\n7. Turn over, remove the paper and allow the cake to cool.\\n8. Ice on the bottom side.\\n9. When ready for serving, cut in 2-inch squares.\\n\\nFor the icing:\\n- 1 egg-white\\n- 1 T cream\\n- 1 t vanilla\\n- 1/2 t lemon extract\\n- 2 C powdered sugar\\n\\nInstructions:\\n1. Beat the egg-white, add part of the sugar.\\n2. Add the cream, vanilla and lemon extracts.\\n3. Keep beating.\\n4. Add the rest of the sugar gradually. (A little more sugar may be needed.)\\n5. Beat the icing till very fluffy and until it will spread without running off the cake.\\n6. Spread each layer.')],\n",
              " 'answer': ' Here is a recipe for Small Cakes from the provided context:\\n\\nIngredients:\\n- 1-1/4 C sugar\\n- 1/3 C butter\\n- 2 C flour\\n- 4 t baking powder\\n- 1/8 t salt\\n- 2/3 C milk\\n- 1 t vanilla\\n- 1/2 t lemon extract\\n- 2 egg-whites\\n\\nInstructions:\\n1. Cream the butter, add the sugar slowly and continue creaming.\\n2. Mix and sift the flour, baking powder and salt and add these and the milk, vanilla and lemon extracts to the butter and sugar. Mix well and beat 2 minutes.\\n3. Beat the egg-whites till very stiff and fold these very carefully into the cake mixture.\\n4. Fill the cake pans (prepared with waxed paper) 2/3 inches deep with the mixture.\\n5. Bake 25 minutes in a moderate oven.\\n6. Allow to stand 5 minutes, then slip a knife around the edges and remove the cake carefully from the pan.\\n7. Turn over, remove the paper and allow the cake to cool.\\n8. Ice on the bottom side.\\n9. When ready for serving, cut in 2-inch squares.\\n\\nFor the icing:\\n- 1 egg-white\\n- 1 T cream\\n- 1 t vanilla\\n- 1/2 t lemon extract\\n- 2 C powdered sugar\\n\\nInstructions:\\n1. Beat the egg-white, add part of the sugar.\\n2. Add the cream, vanilla and lemon extracts.\\n3. Keep beating.\\n4. Add the rest of the sugar gradually. (A little more sugar may be needed.)\\n5. Beat the icing till very fluffy and until it will spread without running off the cake.\\n6. Spread each layer.',\n",
              " 'source_documents': [Document(page_content='=Small Cakes= (Fourteen cakes)\\n\\n    1-1/4 C-sugar\\n    1/3 C-butter\\n    2 C-flour\\n    4 t-baking powder\\n    1/8 t-salt\\n    2/3 C-milk\\n    1 t-vanilla\\n    1/2 t-lemon extract\\n    2 egg-whites\\n\\nCream the butter, add the sugar slowly and continue creaming. Mix and\\nsift the flour, baking powder and salt and add these and the milk,\\nvanilla and lemon extracts to the butter and sugar. Mix well and beat\\ntwo minutes. Beat the egg-whites till very stiff and fold these very\\ncarefully into the cake mixture. When thoroughly mixed, fill the cake\\npans (which have been prepared with waxed paper) two-thirds of an inch\\ndeep with the mixture.\\n\\nBake twenty-five minutes in a moderate oven, allow to stand five\\nminutes, then slip a knife around the edges and remove the cake\\ncarefully from the pan. Turn over, remove the paper and allow the cake\\nto cool. Ice on the bottom side. When ready for serving, cut in two-inch\\nsquares.\\n\\n\\n=Bettina Icing=\\n\\n1 egg-white 1 T-cream 1 t-vanilla 1/2 t-lemon extract 2 C-powdered sugar\\n\\nBeat the egg-white add part of the sugar. Add the cream, vanilla and\\nlemon extracts. Keep beating. Add the rest of the sugar gradually. (A\\nlittle more sugar may be needed.) Beat the icing till very fluffy and\\nuntil it will spread without running off the cake. Spread each layer.\\n\\n\\n\\n\\nCHAPTER CXXVII\\n\\nA SHAMROCK LUNCHEON\\n\\n\\nBETTINA was entertaining \"the crowd\" at a shamrock luncheon, and each\\nguest, to show her enthusiasm for the charms of \"ould Ireland,\" was\\nwearing somewhere upon her gown, a bit of green.\\n\\nA green basket filled with white carnations and green foliage stood in\\nthe center of the table. White glass candlesticks with green shades also\\ncarried out the color scheme, while white crocheted favor baskets,\\nfilled with dainty green candies, were at each plate. The table was set\\nfor six.\\n\\nThe name cards were white shamrocks outlined with green ink and edged\\nwith gilt, and the name on each was written in green.\\n\\nBettina used green ferns for decoration in every possible place where\\nthey might add to the attractiveness of the table, under the glass\\ndishes and around the baskets containing rolls, cakes and croutons.\\n\\n\"You might be Irish yourself, Bettina,\" said Mary, \"you have such a\\nfeeling for green! And isn\\'t the table lovely, girls!\"\\n\\nFor luncheon Bettina served:\\n\\n                         Grapefruit Cocktail\\n    Cream of Celery Soup                     Shamrock Croutons\\n        Bettina Meat Timbales                  Brown Sauce\\n                         Asparagus on Toast\\n                   Mashed Sweet Potato Croquettes\\n            Shamrock Rolls                   Mint Jelly\\n               Pepper Salad              Sandwiches\\n                   Bombe Glace   Shamrock Cakes\\n                              Coffee\\n                         Shamrock Candies\\n\\n\\nBETTINA\\'S RECIPES\\n\\n(All measurements are level)\\n\\n\\n=Grapefruit Cocktail= (Six portions)\\n\\n    2 grapefruit\\n    1/3 C-sugar\\n    6 green cherries\\n    Smilax or fern leaves\\n\\nPeel the grapefruit, remove the white part and the tough membrane,\\nleaving the fruit. Cut with the scissors into one-inch cubes. Place in a\\nbowl, add the sugar and allow to stand in a cold place for one hour.\\nArrange the servings in six sherbet glasses. Place one green cherry on\\nthe top of each and garnish the plate with smilax or a fern leaf. Stand\\nthe sherbet glasses on a paper doily on a small serving plate. Arrange a\\nbit of the green leaf under the sherbet glass (on top of the doily) so\\nthat the green color will be visible through the glass.\\n\\n\\n=Cream of Celery Soup= (Six portions)\\n\\n    2/3 C-celery, cut fine\\n    1-1/2 C-water\\n    4 T-butter\\n    6 T-flour\\n    2-1/2 C-milk\\n    2 t-salt\\n    1/4 t-paprika\\n    1 t-chopped parsley\\n    2 T-whipped cream', metadata={'source': '/content/A_Thousand_Ways_to_Please_a_Husband'}),\n",
              "  Document(page_content='Bake in a tin where the mixture comes about one inch and a half thick,\\npreviously greasing the tin with cold butter and sprinkle with powdered\\nsugar mixed with flour.\\n\\nIn these cakes with beaten whites the following method can also be\\nfollowed: mix and stir first the yolks with the sugar, then put the\\nflour then, after a good kneading, beat the whites until they are firm,\\npour two tablespoonfuls to soften the mixture, then the rest little by\\nlittle.\\n\\n\\n192\\n\\nCAKE MADELEINE\\n\\n(Pasta Maddalena)\\n\\n  Sugar, four and a half ounces,\\n  Flour, three ounces,\\n  Butter, one ounce,\\n  Egg-yolks, four,\\n  Whites of eggs, three,\\n  A pinch of bi-carbonate of soda,\\n  A taste of lemon peel.\\n\\nFirst mix and stir the yolks with the sugar and when they have become\\nwhitish, add the flour and stir for fifteen minutes more. Mix with the\\nbutter, melting or softening it fine if it is hard and finally add the\\nwhites when they are well beaten. The flour must be previously dried in\\nthe sun or on the fire.\\n\\nThis cake may be given different shapes, but keep it always thin and in\\nlittle volume. It can be put in little molds greased with butter and\\nsprinkled with flour, or else in a baking tin, keeping it not more than\\nhalf an inch thick, and cutting it after baking in the shape of diamonds\\nand dusting with powdered sugar.\\n\\n\\n193\\n\\nALMOND CRISP-TART\\n\\n(Croccante)\\n\\n  Sweet almonds, four and a half ounces.\\n  Granulated sugar, three and a half ounces.\\n\\nSkin the almonds, divide the two parts and cut each part into small\\npieces. Put these almonds so cut at the fire and dry them until they\\ntake a yellowish color, but do not toast. Meanwhile put the sugar on the\\nfire in a saucepan and, when it is perfectly melted, pour the almonds\\nhot and already slightly browned. Now lower the fire and be careful not\\nto allow the compound to be overdone. The precise point is known when\\nthe mixture acquires a cinnamon color. Then pour little by little in a\\ncold mold, previously greased with butter or oil. Press with a lemon\\nagainst the walls of the mold, making the mixture as thin as possible.\\nRemove from the mold when perfectly cooled and, if it is difficult to do\\nso, dip the mold in boiling water.\\n\\nThe almonds can also be dried in the sun and chopped fine, adding a\\nsmall piece of butter when they are in the sugar.\\n\\n\\n194\\n\\nWAFER BISCUITS\\n\\n(Cialdoni)\\n\\nPut in a kettle:\\n\\n  Flour, three ounces.\\n  Brown sugar, one ounce.\\n  Lard virgin, half an ounce.\\n  Cold water, seven tablespoonfuls.\\n\\nFirst dilute the flour and the sugar in the water, then add the lard.\\n\\nPut on the fire the iron for waffles or better an appropriated iron for\\nflattened wafers. When it is quite hot open it and place each time half\\na tablespoonful of the paste. Close the iron and press well. Pass over\\nthe fire on both sides, trim all around with a knife and open the iron\\nwhen you see that the wafer is browned. Then detach it from one side of\\nthe iron and hot as it is roll it on the iron itself or on a napkin\\nusing a little stick. This operation must be made with great rapidity\\nbecause if the wafer gets cold, it cannot be rolled.\\n\\nShould the wafers remain attached to the iron, grease it from time to\\ntime, and if they are not firm enough, add a little flour.\\n\\nThese wafer-biscuits are generally served with whipped cream.\\n\\n\\n195\\n\\nQUINCE CAKE\\n\\n(Cotognata)\\n\\nThe ingredients are about six pounds of quinces and four pounds of\\ngranulated sugar.\\n\\nPut on the fire the apples covered with water, and when they begin to\\ncrack remove them, skin and scrape to put together all the pulp. Rub the\\nlatter through a sieve. Put back the pulp on the fire with the sugar and\\nstir continually in order that it may not attack to the bottom of the\\nkettle. It will be enough to boil for seven or eight minutes and remove\\nwhen it begins to form pieces when lifted with the ladle.', metadata={'source': '/content/The_Italian_Cook_Book'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "chain.invoke(\"Give me a cake recipe?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3kjx1sQbOUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "eb3c02dc-1589-4f49-8566-a108f2d3b200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The term \"cake\" originates from the Old Norse word \"kaka\", which means \"to bake\". Therefore, in its original language, a cake is called a \"kaka\".\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke(\"What is a cake?\")['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WoUJYsSbORb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a850d6-4482-48e4-ed59-f2bd85a15889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  To make a vanilla cake, you can use the following recipe:\n",
            "\n",
            "Ingredients:\n",
            "- 2 cups all-purpose flour\n",
            "- 1 cup sugar\n",
            "- 1/2 cup butter (or margarine)\n",
            "- 1 1/2 teaspoons baking powder\n",
            "- 1/2 teaspoon baking soda\n",
            "- 1/2 teaspoon salt\n",
            "- 1 cup milk\n",
            "- 1 teaspoon vanilla extract\n",
            "- 2 eggs\n",
            "\n",
            "Instructions:\n",
            "1. Preheat the oven to 350°F (180°C). Grease and flour a 9-inch round cake pan.\n",
            "2. In a large bowl, cream the sugar and butter together.\n",
            "3. Add the eggs, one at a time, beating well after each addition.\n",
            "4. In a separate bowl, sift together the flour, baking powder, baking soda, and salt.\n",
            "5. Add half of the flour mixture to the butter and sugar mixture, then add the milk and vanilla extract. Mix well.\n",
            "6. Add the remaining flour mixture and mix until just combined.\n",
            "7. Pour the batter into the prepared cake pan and smooth the top with a spatula.\n",
            "8. Bake for 30-35 minutes, or until a toothpick inserted into the center of the cake comes out clean.\n",
            "9. Let the cake cool in the pan for 10 minutes, then remove it from the pan and let it cool completely on a wire rack.\n",
            "10. Ice the cake with your favorite frosting, if desired.\n",
            "\n",
            "Enjoy your vanilla cake!\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke(\"Explain the vanilla cake\")['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLey0WO_owAP"
      },
      "source": [
        "## Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test 1"
      ],
      "metadata": {
        "id": "XhKeXO9GIXuQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPysmVaMbOLi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -qqq -U streamlit\n",
        "!npm install -qqq -U localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJQR6Vm1qcA5"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import streamlit as st\n",
        "\n",
        "# llm\n",
        "hf_model= \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "#llm = HuggingFaceEndpoint(repo_id=hf_model)\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id = hf_model,\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.8,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    typical_p=0.92,\n",
        "    repetition_penalty=1.15)\n",
        "\n",
        "# embeddings\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n",
        "                                   cache_folder=embeddings_folder)\n",
        "\n",
        "# load Vector Database\n",
        "# allow_dangerous_deserialization is needed.\n",
        "vector_db = FAISS.load_local(\"/content/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "# retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# memory\n",
        "@st.cache_resource\n",
        "def init_memory(_llm):\n",
        "    return ConversationBufferMemory(\n",
        "        llm=llm,\n",
        "        output_key='answer',\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True)\n",
        "memory = init_memory(llm)\n",
        "\n",
        "# prompt\n",
        "Response= st.selectbox (\"In which tone would you like me to talk to you:\", (\"Sassy\", \"Funny\", \"Formal\", \"Rude\"))\n",
        "\n",
        "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
        "Answer the question based only on the following context and previous conversation. Keep your answers {Response}.\n",
        "\n",
        "Previous conversation:\n",
        "{chat_history}\n",
        "\n",
        "Context to answer question:\n",
        "{context}\n",
        "\n",
        "New human question: {question}\n",
        "Response:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template,\n",
        "                        input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# chain\n",
        "chain = ConversationalRetrievalChain.from_llm(llm,\n",
        "                                              retriever=retriever,\n",
        "                                              memory=memory,\n",
        "                                              return_source_documents=True,\n",
        "                                              combine_docs_chain_kwargs={\"prompt\": prompt})\n",
        "\n",
        "\n",
        "##### streamlit #####\n",
        "\n",
        "st.title(\"Welcome to the red[OMG] Chat Room :sunglasses:\")\n",
        "\n",
        "#st.markdown(Travel_pic, unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialise chat history\n",
        "# Chat history saves the previous messages to be displayed\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# React to user input\n",
        "if prompt := st.chat_input(\"Talk to me\"):\n",
        "\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    # Begin spinner before answering question so it's there for the duration\n",
        "    with st.spinner(\"Mmmh thinking, ideas flowing...\"):\n",
        "\n",
        "        # send question to chain to get answer\n",
        "        answer = chain(prompt)\n",
        "\n",
        "        # extract answer from dictionary returned by chain\n",
        "        response = answer[\"answer\"]\n",
        "\n",
        "        # Display chatbot response in chat message container\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.markdown(answer[\"answer\"])\n",
        "\n",
        "        # Add assistant response to chat history\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3FPrATwqb99"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test 2"
      ],
      "metadata": {
        "id": "oKsXuLMcIT-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_app.py\n",
        "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import streamlit as st\n",
        "import base64\n",
        "# Function to add background image\n",
        "def add_bg_from_local(Travel_pic):\n",
        "    with open(Travel_pic, \"rb\") as image:\n",
        "        encoded_string = base64.b64encode(image.read())\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        .stApp {{\n",
        "            background-image: url(data:image/{\"png\"};base64,{encoded_string.decode()});\n",
        "            background-size: cover;\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "# Set the background image\n",
        "add_bg_from_local('/content/Travel_pic')\n",
        "# Title of the app\n",
        "st.title(\"Welcome to the Travel and Food Recipe Chatbot\")\n",
        "# Introduction text\n",
        "st.write(\"Welcome to the Travel and Food Recipe Chatbot! Let's plan your next trip or meal.\")\n",
        "# Option to choose between travel or food suggestion\n",
        "choice = st.radio(\n",
        "    \"Would you like to:\",\n",
        "    (\"Get a travel itinerary\", \"Get a meal suggestion\")\n",
        ")\n",
        "if choice == \"Get a travel itinerary\":\n",
        "    # User input for travel destinations\n",
        "    locations = st.text_input(\"What are the top 3 locations on your bucket list? (separate by commas)\")\n",
        "    if locations:\n",
        "        # Split the input into a list\n",
        "        location_list = [location.strip() for location in locations.split(\",\")]\n",
        "        if len(location_list) == 3:\n",
        "            st.write(\"You have selected the following locations:\")\n",
        "            for location in location_list:\n",
        "                st.write(\"- \" + location)\n",
        "            st.write(\"Here is a suggested itinerary for your trip to these locations...\")\n",
        "            # Here you would add the logic for generating the itinerary\n",
        "        else:\n",
        "            st.warning(\"Please enter exactly 3 locations separated by commas.\")\n",
        "elif choice == \"Get a meal suggestion\":\n",
        "    # User input for items in the fridge\n",
        "    fridge_items = st.text_input(\"What do you have in your fridge? (separate items by commas)\")\n",
        "    if fridge_items:\n",
        "        # Split the input into a list\n",
        "        fridge_list = [item.strip() for item in fridge_items.split(\",\")]\n",
        "        st.write(\"You have the following items in your fridge:\")\n",
        "        for item in fridge_list:\n",
        "            st.write(\"- \" + item)\n",
        "        st.write(\"Based on these items, here is a suggested recipe...\")\n",
        "        # Here you would add the logic for generating the recipe\n",
        "# LLM Configuration\n",
        "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=hf_model,\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.8,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    typical_p=0.92,\n",
        "    repetition_penalty=1.15\n",
        ")\n",
        "# Embeddings Configuration\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model, cache_folder=embeddings_folder)\n",
        "# Load Vector Database\n",
        "vector_db = FAISS.load_local(\"/content/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "# Retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "# Memory\n",
        "@st.cache_resource\n",
        "def init_memory(_llm):\n",
        "    return ConversationBufferMemory(\n",
        "        llm=llm,\n",
        "        output_key='answer',\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True\n",
        "    )\n",
        "memory = init_memory(llm)\n",
        "# Prompt\n",
        "Response = st.selectbox(\"In which tone would you like me to talk to you:\", (\"Sassy\", \"Funny\", \"Formal\", \"Rude\"))\n",
        "template = f\"\"\"You are a nice chatbot having a conversation with a human.\n",
        "Answer the question based only on the following context and previous conversation. Keep your answers {Response}.\n",
        "Previous conversation:\n",
        "{{chat_history}}\n",
        "Context to answer question:\n",
        "{{context}}\n",
        "New human question: {{question}}\n",
        "Response:\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "# Chain\n",
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    return_source_documents=True,\n",
        "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
        ")\n",
        "##### Streamlit #####\n",
        "\n",
        "#st.title(\"Welcome to the OMG Chat Room :sunglasses:\")\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "# React to user input\n",
        "if prompt := st.chat_input(\"Talk to me\"):\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    # Begin spinner before answering question so it's there for the duration\n",
        "    with st.spinner(\"Mmmh thinking, ideas flowing...\"):\n",
        "        # Send question to chain to get answer\n",
        "        answer = chain(prompt)\n",
        "        # Extract answer from dictionary returned by chain\n",
        "        response = answer[\"answer\"]\n",
        "        # Display chatbot response in chat message container\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.markdown(answer[\"answer\"])\n",
        "        # Add assistant response to chat history\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
      ],
      "metadata": {
        "id": "7xCfbRglC9AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run test_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "zQw4vfrLC88v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test 3"
      ],
      "metadata": {
        "id": "oI87Mc-fIQGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_app2.py\n",
        "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import streamlit as st\n",
        "import base64\n",
        "# Function to add background image\n",
        "def add_bg_from_local(image_file):\n",
        "    with open(image_file, \"rb\") as image:\n",
        "        encoded_string = base64.b64encode(image.read())\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        .stApp {{\n",
        "            background-image: url(data:image/{\"png\"};base64,{encoded_string.decode()});\n",
        "            background-size: cover;\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "# Set the background image\n",
        "add_bg_from_local('/content/Travel_pic')\n",
        "# Title of the app\n",
        "st.title(\"Travel and Food Recipe Chatbot\")\n",
        "# Introduction text\n",
        "st.write(\"Welcome to the Travel and Food Recipe Chatbot! Let's plan your next trip or meal.\")\n",
        "# Option to choose between travel or food suggestion\n",
        "choice = st.radio(\n",
        "    \"Would you like to:\",\n",
        "    (\"Get a travel itinerary, \"Get a meal suggestion\")\n",
        ")\n",
        "if choice == \"Get a travel itinerary\":\n",
        "    # User input for travel destinations\n",
        "    locations = st.text_input(\"What are the top 3 locations on your bucket list? (separate by commas)\")\n",
        "    if locations:\n",
        "        # Split the input into a list\n",
        "        location_list = [location.strip() for location in locations.split(\",\")]\n",
        "        if len(location_list) == 3:\n",
        "            st.write(\"You have selected the following locations:\")\n",
        "            for location in location_list:\n",
        "                st.write(\"- \" + location)\n",
        "            st.write(\"Here is a suggested itinerary for your trip to these locations...\")\n",
        "            # Here you would add the logic for generating the itinerary\n",
        "        else:\n",
        "            st.warning(\"Please enter exactly 3 locations separated by commas.\")\n",
        "elif choice == \"Get a meal suggestion\":\n",
        "    # User input for items in the fridge\n",
        "    fridge_items = st.text_input(\"What do you have in your fridge? (separate items by commas)\")\n",
        "    if fridge_items:\n",
        "        # Split the input into a list\n",
        "        fridge_list = [item.strip() for item in fridge_items.split(\",\")]\n",
        "        st.write(\"You have the following items in your fridge:\")\n",
        "        for item in fridge_list:\n",
        "            st.write(\"- \" + item)\n",
        "        st.write(\"Based on these items, here is a suggested recipe...\")\n",
        "        # Here you would add the logic for generating the recipe"
      ],
      "metadata": {
        "id": "27TyP4OZC8hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run test_app2.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "Pza2GSFUIIQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test 4"
      ],
      "metadata": {
        "id": "XGqWk0leWeo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_app3.py\n",
        "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import streamlit as st\n",
        "import base64\n",
        "\n",
        "# LLM Configuration\n",
        "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=hf_model,\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.8,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    typical_p=0.92,\n",
        "    repetition_penalty=1.15\n",
        ")\n",
        "\n",
        "# Embeddings Configuration\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model, cache_folder=embeddings_folder)\n",
        "\n",
        "# Load Vector Database\n",
        "vector_db = FAISS.load_local(\"/content/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "# Retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# Initialize Memory\n",
        "@st.cache_resource\n",
        "def init_memory(llm_instance):\n",
        "    return ConversationBufferMemory(\n",
        "        llm=llm_instance,\n",
        "        output_key='answer',\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True\n",
        "    )\n",
        "memory = init_memory(llm)\n",
        "\n",
        "# User Selection for Tone and Topic\n",
        "tone = st.selectbox(\"In which tone would you like me to talk to you:\", (\"Sassy\", \"Funny\", \"Formal\", \"Rude\"))\n",
        "topic = st.selectbox(\"Select a conversation topic:\", (\"Travel\", \"Food\", \"Other\"))\n",
        "\n",
        "# Prompt Configuration\n",
        "template = f\"\"\"\n",
        "You are a nice chatbot having a conversation with a human.\n",
        "Tailor your responses towards the topic of {topic}. Answer the question based only on the following context and previous conversation. Keep your answers {tone}.\n",
        "Previous conversation:\n",
        "{{chat_history}}\n",
        "Context to answer question:\n",
        "{{context}}\n",
        "New human question: {{question}}\n",
        "Response:\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# Conversational Chain\n",
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    return_source_documents=True,\n",
        "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
        ")\n",
        "\n",
        "# Streamlit App\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"Chatbot App\", page_icon=\":robot_face:\")\n",
        "\n",
        "# Add background image using CSS\n",
        "background_image = \"\"\"\n",
        "<style>\n",
        "body {\n",
        "    background-image: url(\"https://drive.google.com/file/d/12NU-O4qRGxetIqVbm5bichtiG1hmOeBP/view?usp=drive_link\");\n",
        "    background-size: cover;\n",
        "    background-position: center;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "st.markdown(background_image, unsafe_allow_html=True)\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# React to user input\n",
        "user_input = st.chat_input(\"Talk to me\")\n",
        "if user_input:\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(user_input)\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Begin spinner before answering question\n",
        "    with st.spinner(\"Mmmh thinking, ideas flowing...\"):\n",
        "        # Send question to chain to get answer\n",
        "        answer = chain(user_input)\n",
        "        # Extract answer from dictionary returned by chain\n",
        "        response = answer[\"answer\"]\n",
        "\n",
        "        # Display chatbot response in chat message container\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.markdown(response)\n",
        "        # Add assistant response to chat history\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ],
      "metadata": {
        "id": "u4ynSX74Wgv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run test_app3.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "nFgiiEgxXDpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FINAL VERSION"
      ],
      "metadata": {
        "id": "-LTt2Qbz9t_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import streamlit as st\n",
        "import base64\n",
        "\n",
        "# Title of the app\n",
        "st.title(\"Exploring the Beauties of the World Together 🤩 ✈️ 🍝 🏄‍♀️\")\n",
        "\n",
        "# Introduction text\n",
        "st.write(\"Tell me, what are you wondering about my darling :heart:?\" )\n",
        "\n",
        "# Set page configuration\n",
        "#st.set_page_config(page_title=\"Chatbot App\", page_icon=\":robot_face:\")\n",
        "\n",
        "# Add background image using CSS\n",
        "background_image = \"\"\"\n",
        "<style>\n",
        "body {\n",
        "    background-image: url(\"https://drive.google.com/uc?id=12NU-O4qRGxetIqVbm5bichtiG1hmOeBP\");\n",
        "    background-size: cover;\n",
        "    background-position: center;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "st.markdown(background_image, unsafe_allow_html= True)\n",
        "\n",
        "# LLM Configuration\n",
        "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=hf_model,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.8,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    typical_p=0.92,\n",
        "    repetition_penalty=1.15\n",
        ")\n",
        "\n",
        "# Embeddings Configuration\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model, cache_folder=embeddings_folder)\n",
        "\n",
        "# Load Vector Database\n",
        "vector_db = FAISS.load_local(\"/content/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "# Retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# Memory\n",
        "@st.cache_resource\n",
        "def init_memory(_llm):\n",
        "    return ConversationBufferMemory(\n",
        "        llm=llm,\n",
        "        output_key='answer',\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True\n",
        "    )\n",
        "memory = init_memory(llm)\n",
        "\n",
        "# Prompt for tone and topic of response\n",
        "Response = st.selectbox(\"In which tone would you like me to talk to you:\", (\"Formal\", \"Sassy and Funny\", \"Rude\"))\n",
        "Topic = st.selectbox(\"Which topic would you like to talk about:\", (\"Food\", \"Travel\", \"General Knowledge\"))\n",
        "\n",
        "# Function to generate response using selected tone\n",
        "def generate_response(prompt, tone):\n",
        "    template = f\"\"\"You are a nice chatbot having a conversation with a human.\n",
        "Answer the question based only on the following context and previous conversation. Keep your answers in a {tone} tone.\n",
        "Previous conversation:\n",
        "{{chat_history}}\n",
        "Context to answer question:\n",
        "{{context}}\n",
        "New human question: {{question}}\n",
        "Response:\"\"\"\n",
        "    prompt_template = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm,\n",
        "        retriever=retriever,\n",
        "        memory=memory,\n",
        "        return_source_documents=True,\n",
        "        combine_docs_chain_kwargs={\"prompt\": prompt_template}\n",
        "    )\n",
        "    return chain(prompt)\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# React to user input\n",
        "if user_input := st.chat_input(\"Talk to me\"):\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(user_input)\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    # Begin spinner before answering question so it's there for the duration\n",
        "    with st.spinner(\"Mmmh thinking, ideas flowing...\"):\n",
        "        # Send question to chain to get answer\n",
        "        answer = generate_response(user_input, Response)\n",
        "        # Extract answer from dictionary returned by chain\n",
        "        response = answer[\"answer\"]\n",
        "        # Display chatbot response in chat message container\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.markdown(response)\n",
        "        # Add assistant response to chat history\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ],
      "metadata": {
        "id": "E0wxBtvF9VvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "YP_mmbo69e99"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}